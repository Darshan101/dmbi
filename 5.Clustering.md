**1. What is hierarchical clustering ? Explain any two techniques for finding distance between the clusters in hierarchical clustering ?**

- Hierarchical methods divides all the data sets into hierarchy
- Problem with the hierarchical methods is once the cluster formed you can not undo it.
- This type of clustering is very useful for the data visulization and summarization.

  Example 1: Summarization of employees as staff, senior officers , officers, trainee etc.
  Example 2: Handwriteen digits can be grouped so that they belong to a unique character.Further it can be divided based on the style. 	      

Types of Hierarchical Clustering : Agglomerative or divisive

Agglomerative: 

- An agglomerative hierarchical clustering method uses a bottom-up strategy. 
- It typically starts by letting each object form its own cluster and iteratively merges clusters
  into larger and larger clusters, until all the objects are in a single cluster or certain termination conditions are 	 satisfied
- The single cluster becomes the hierarchy’s root
- For the merging step, it finds the two clusters that are closest to each other
- Two clusters are merged per iteration, an agglomerative method requires at most n iterations.


Divisive :

- Divisive hierarchical clustering method employs a top-down strategy
- It starts by placing all objects in one cluster, which is the hierarchy’s root
- It then divides the root cluster into several smaller subclusters, and recursively partitions those clusters into
smaller ones.
- The partitioning process continues until each cluster at the lowest level is coherent enough—either containing only one object, or the objects within a cluster are sufficiently similar to each other.


![Table 4.1](/Images/Figure_5.1.png)


In both Agglomerative or Divisive hierarchical clustering, a user can specify the desired number of clusters as a termination condition.

![Table 4.1](/Images/Figure_5.2.png)

A tree structure called a dendrogram is commonly used to represent the process of
hierarchical clustering. It shows how objects are grouped together (in an agglomerative
method) or partitioned (in a divisive method) step-by-step.


![Table 4.1](/Images/Figure5.3.png)

Measures for distance between the clusters 




**2. Use any hierarchical clustering algorithm to cluster the following 8 examples into three clusters**

A1 = (2,10)
A2 = (2,5)
A3 = (8,4)
A4 = (5,8)
A5 = (7,5)
A6 = (6,4)
A7 = (1,2)
A8 = (4,9) 


**3. Clearly explain the DBSCAN algorithm using appropriate algorithms.**

**4. Explain BIRCH algorithm with example**

**5. What is clustering ? Explain k-means clustering alogrithm. Suppose the data for clustering **
   ** { 2, 4, 10, 12, 3, 20, 11, 25 } consider k = 2, cluster the given data using above algorithm.**


**6. Use k-means to cluster the following data into 3 clusters.**

Protin and Fat (20,9), (21,9), (15,7), (22,17), (20,8), (25,12), (26,14), (20,9), (18,9), (20,9)

 


